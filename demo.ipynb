{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c989f41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Title](images/title-page.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ad24f-5035-4c5d-81e4-a81d9dff1e9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Title](images/title-qr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed161285-5c6c-41de-a4ad-685a5de5ba0e",
   "metadata": {},
   "source": [
    "### What is the TPC?\n",
    "The TPC is a non-profit corporation focused on developing data-centric benchmark standards and disseminating objective, verifiable data to the industry.\n",
    "\n",
    "[tpc.org](https://www.tpc.org)\n",
    "\n",
    "### What is TPC-DI?\n",
    "The TPC-DI benchmark combines and transforms data extracted from an On-Line Transaction Processing (OTLP) system along with other sources of data, and loads it into a data warehouse.\n",
    "\n",
    "[tpc.org/tpcdi](https://www.tpc.org/tpcdi/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9e518-484a-4f18-80d4-4ae43c72312a",
   "metadata": {},
   "source": [
    "![ETL Diagram](images/tpc-di-etl-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPC-DI provides `DIGen.jar` to generate the source files.\n",
    "\n",
    "The JAR is dated and requires a 1.8 JDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jenv local 1.8\n",
    "!java -jar ~/dev/Tools/DIGen.jar --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/dev/tpcdi-output\n",
    "!mkdir -p ~/dev/tpcdi-output\n",
    "!cd ~/dev/Tools && java -jar ~/dev/Tools/DIGen.jar -o ~/dev/tpcdi-output -sf 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GitHub repository has a prebuilt CLI for easily loading the files.\n",
    "[github.com/stewartbryson/dbt-tpcdi](https://www.github.com/stewartbryson/dbt-tpcdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tpcdi.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tpcdi.py process-files --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tpcdi.py process-files --output-directory ~/dev/tpcdi-output --file-name DailyMarket.txt --show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you get nothing else from this video, know that there's an easy way to load this dataset into Snowflake.\n",
    "\n",
    "But I also wanted to show some interesting approaches using Snowpark.\n",
    "\n",
    "All of the code samples below are snippets from the CLI with abstractions removed.\n",
    "\n",
    "We start with a `credentials.json` file to store our Snowflake credentials. Something like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"account\": \"myaccount\",\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"role\": \"myrole\",\n",
    "    \"warehouse\": \"stewart_dev\",\n",
    "    \"database\": \"tpcdi\",\n",
    "    \"schema\": \"digen\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a Snowflake session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from snowflake.snowpark.types import *\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Read the credentials.json file\n",
    "with open(\"credentials.json\") as jsonfile:\n",
    "    credentials_dict = json.load(jsonfile)\n",
    "\n",
    "# build the session\n",
    "session = (\n",
    "    Session\n",
    "    .builder\n",
    "    .configs(credentials_dict)\n",
    "    .create()\n",
    ")\n",
    "\n",
    "# Constants\n",
    "source_path = '/Users/stewartbryson/dev/tpcdi-output/Batch1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the files generated by `DIGen.jar` are pipe-separated files, very similar to CSV files.\n",
    "\n",
    "These are very simple to handle. First let's upload the file to a stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "stage_path = \"@tpcdi/Batch1\"\n",
    "\n",
    "# Put the file\n",
    "put_result = (\n",
    "    session\n",
    "    .file\n",
    "    .put(\n",
    "        f\"{source_path}/DailyMarket.txt\",\n",
    "        f\"{stage_path}/DailyMarket.txt\",\n",
    "        parallel=4,\n",
    "        auto_compress=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Report back file results\n",
    "for result in put_result:\n",
    "    print(f\"File {result.source}: {result.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll create a table from that file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'daily_market'\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "                StructField(\"DM_DATE\", DateType(), False),\n",
    "                StructField(\"DM_S_SYMB\", StringType(), False),\n",
    "                StructField(\"DM_CLOSE\", FloatType(), False),\n",
    "                StructField(\"DM_HIGH\", FloatType(), False),\n",
    "                StructField(\"DM_LOW\", FloatType(), False),\n",
    "                StructField(\"DM_VOL\", FloatType(), False),\n",
    "        ])\n",
    "\n",
    "# create a table from a DataFrame\n",
    "df = (\n",
    "    session\n",
    "    .read\n",
    "    .schema(schema)\n",
    "    .option(\"field_delimiter\", '|')\n",
    "    .csv(f\"{stage_path}/DailyMarket.txt\")\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table(table_name)\n",
    ")\n",
    "\n",
    "print(f\"{table_name.upper()} table created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the table\n",
    "df = (\n",
    "    session \n",
    "    .table(table_name) \n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DIGen.jar` utility generates a series of \"finwire\" files.\n",
    "\n",
    "These files represent market history over time.\n",
    "\n",
    "They are fixed-width, multi-format files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a sample of one of the files that has one of each type of record: `FIN`, `SEC`, and `CMP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat devrel/multi-record.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by uploading all the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# File paths\n",
    "stage_path = \"@tpcdi/Batch1/FINWIRE\"\n",
    "\n",
    "# glob the files\n",
    "pathlist = (\n",
    "    Path(source_path)\n",
    "    .glob(\"FINWIRE??????\")\n",
    ")\n",
    "\n",
    "for file in pathlist:\n",
    "    # put the file(s) in the stage\n",
    "    put_result = (\n",
    "        session \n",
    "        .file\n",
    "        .put(\n",
    "            str(file), \n",
    "            stage_path, \n",
    "            parallel=4, \n",
    "            auto_compress=True\n",
    "        )\n",
    "    )\n",
    "    for result in put_result:\n",
    "        print(f\"File {result.source}: {result.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CMP`, `SEC`, and `FIN` records all have two fields in common, so we want to create a generic DataFrame that contains the shared logic and weâ€™ll save that DataFrame as a Snowflake temporary table called `FINWIRE`. We'll use `WITH_COLUMN` and `SUBSTRING`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are fixed-width fields, so read the entire line in as \"line\"\n",
    "schema = StructType([\n",
    "        StructField(\"line\", StringType(), False),\n",
    "])\n",
    "\n",
    "# generic dataframe for all record types\n",
    "# create a temporary table\n",
    "# The delimiter '|' seems safer\n",
    "df = (\n",
    "    session\n",
    "    .read\n",
    "    .schema(schema)\n",
    "    .option('field_delimiter', '|')\n",
    "    .csv(stage_path)\n",
    "    .with_column(\n",
    "        'pts', \n",
    "        to_timestamp(\n",
    "            substring(col(\"line\"), lit(0), lit(15)), \n",
    "            lit(\"yyyymmdd-hhmiss\")\n",
    "        )\n",
    "    )\n",
    "    .with_column(\n",
    "        'rec_type', \n",
    "        substring(col(\"line\"), lit(16), lit(3))\n",
    "    )\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table(\"finwire\", table_type=\"temporary\")\n",
    ")\n",
    "\n",
    "# let's see the table\n",
    "df = (\n",
    "    session \n",
    "    .table('finwire') \n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the three separate tables from this temporary table using the `WITH_COLUMN` and `SUBSTRING` functions.\n",
    "\n",
    "I'll only show the Security table as an example, but the other two are done the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEC record types\n",
    "table_name = 'sec'\n",
    "df = (\n",
    "    session\n",
    "    .table('finwire')\n",
    "    .where(col('rec_type') == 'SEC')\n",
    "    .withColumn(\n",
    "        'symbol', \n",
    "        substring(col(\"line\"), lit(19), lit(15))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'issue_type', \n",
    "        substring(col(\"line\"), lit(34), lit(6))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'status', \n",
    "        substring(col(\"line\"), lit(40), lit(4))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'name', \n",
    "        substring(col(\"line\"), lit(44), lit(70))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'ex_id', \n",
    "        substring(col(\"line\"), lit(114), lit(6))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'sh_out', \n",
    "        substring(col(\"line\"), lit(120), lit(13))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'first_trade_date', \n",
    "        substring(col(\"line\"), lit(133), lit(8))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'first_exchange_date', \n",
    "        substring(col(\"line\"), lit(141), lit(8))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'dividend', \n",
    "        substring(col(\"line\"), lit(149), lit(12))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'co_name_or_cik', \n",
    "        substring(col(\"line\"), lit(161), lit(60))\n",
    "    )\n",
    "    # these columns are no longer relevant\n",
    "    .drop(col(\"line\"), col(\"rec_type\"))\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table(table_name)\n",
    ")\n",
    "\n",
    "print(f\"{table_name.upper()} table created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# let's see the table\n",
    "df = (\n",
    "    session \n",
    "    .table('sec') \n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DIGen.jar` utility creates a single XML file called `CustomerMgmt.xml`, with a sample below:\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<TPCDI:Actions xmlns:TPCDI=\"http://www.tpc.org/tpc-di\">\n",
    " <TPCDI:Action ActionType=\"NEW\" ActionTS=\"2007-07-07T02:56:25\">\n",
    "  <Customer C_ID=\"0\" C_TAX_ID=\"923-54-6498\" C_GNDR=\"F\" C_TIER=\"3\" C_DOB=\"1940-12-02\">\n",
    "   <Name>\n",
    "    <C_L_NAME>Joannis</C_L_NAME>\n",
    "    <C_F_NAME>Adara</C_F_NAME>\n",
    "    <C_M_NAME/>\n",
    "   </Name>\n",
    "   <Address>\n",
    "    <C_ADLINE1>4779 Weller Way</C_ADLINE1>\n",
    "    <C_ADLINE2/>\n",
    "    <C_ZIPCODE>92624</C_ZIPCODE>\n",
    "    <C_CITY>Columbus</C_CITY>\n",
    "    <C_STATE_PROV>Ontario</C_STATE_PROV>\n",
    "    <C_CTRY>Canada</C_CTRY>\n",
    "   </Address>\n",
    "   <ContactInfo>\n",
    "    <C_PRIM_EMAIL>Adara.Joannis@moose-mail.com</C_PRIM_EMAIL>\n",
    "    <C_ALT_EMAIL>Adara.Joannis@gmx.com</C_ALT_EMAIL>\n",
    "    <C_PHONE_1>\n",
    "     <C_CTRY_CODE>1</C_CTRY_CODE>\n",
    "     <C_AREA_CODE>872</C_AREA_CODE>\n",
    "     <C_LOCAL>523-8928</C_LOCAL>\n",
    "     <C_EXT/>\n",
    "    </C_PHONE_1>\n",
    "    <C_PHONE_2>\n",
    "     <C_CTRY_CODE/>\n",
    "     <C_AREA_CODE/>\n",
    "     <C_LOCAL>492-3961</C_LOCAL>\n",
    "     <C_EXT/>\n",
    "    </C_PHONE_2>\n",
    "    <C_PHONE_3>\n",
    "     <C_CTRY_CODE/>\n",
    "     <C_AREA_CODE/>\n",
    "     <C_LOCAL/>\n",
    "     <C_EXT/>\n",
    "    </C_PHONE_3>\n",
    "   </ContactInfo>\n",
    "   <TaxInfo>\n",
    "    <C_LCL_TX_ID>CA3</C_LCL_TX_ID>\n",
    "    <C_NAT_TX_ID>YT3</C_NAT_TX_ID>\n",
    "   </TaxInfo>\n",
    "   <Account CA_ID=\"0\" CA_TAX_ST=\"1\">\n",
    "    <CA_B_ID>17713</CA_B_ID>\n",
    "    <CA_NAME>CJlmMuFyibKOmKLHIaTeWugvCgZdmcfpDsYb</CA_NAME>\n",
    "   </Account>\n",
    "  </Customer>\n",
    " </TPCDI:Action>\n",
    "</TPCDI:Actions>\n",
    "```\n",
    "\n",
    "The hierarchical representation of a TPCDI:Action record, with @ signifying a node attribute as opposed to an element, is shown below:\n",
    "\n",
    "```\n",
    "|-- TPCDI:Action\n",
    "    |-- @ActionType: string\n",
    "    |-- @ActionTS: timestamp\n",
    "    |-- Customer\n",
    "        |-- @C_ID: number\n",
    "        |-- @C_TAX_ID: string\n",
    "        |-- @C_GNDR: string\n",
    "        |-- @C_TIER: number\n",
    "        |-- @C_DOB: date\n",
    "        |-- Name\n",
    "            |-- C_F_NAME: string\n",
    "            |-- C_L_NAME: string\n",
    "            |-- C_M_NAME: string\n",
    "        |-- Address\n",
    "            |-- C_ADLINE1: string\n",
    "            |-- C_ADLINE2: string\n",
    "            |-- C_CITY: string\n",
    "            |-- C_CTRY: string\n",
    "            |-- C_STATE_PROV: string\n",
    "            |-- C_ZIPCODE: string\n",
    "        |-- ContactInfo\n",
    "            |-- C_ALT_EMAIL: string\n",
    "            |-- C_PHONE_1\n",
    "                |-- C_AREA_CODE: number\n",
    "                |-- C_CTRY_CODE: number\n",
    "                |-- C_EXT: long\n",
    "                |-- C_LOCAL: string\n",
    "            |-- C_PHONE_2\n",
    "                |-- C_AREA_CODE: number\n",
    "                |-- C_CTRY_CODE: number\n",
    "                |-- C_EXT: number\n",
    "                |-- C_LOCAL: string\n",
    "            |-- C_PHONE_3\n",
    "                |-- C_AREA_CODE: number\n",
    "                |-- C_CTRY_CODE: number\n",
    "                |-- C_EXT: number\n",
    "                |-- C_LOCAL: string\n",
    "        |-- TaxInfo\n",
    "            |-- C_LCL_TX_ID: string\n",
    "            |-- C_NAT_TX_ID: string\n",
    "        |-- Account\n",
    "            |-- CA_B_ID: number\n",
    "            |-- CA_NAME: string\n",
    "            |-- @CA_ID: number\n",
    "            |-- @CA_TAX_ST: number\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a DataFrame from the XML file and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "stage_path = \"@tpcdi/Batch1\"\n",
    "\n",
    "# Put the file\n",
    "put_result = (\n",
    "    session\n",
    "    .file\n",
    "    .put(\n",
    "        f\"{source_path}/CustomerMgmt.xml\",\n",
    "        f\"{stage_path}/CustomerMgmt.xml\",\n",
    "        parallel=4,\n",
    "        auto_compress=True,\n",
    "    )\n",
    ")\n",
    "for result in put_result:\n",
    "    print(f\"File {result.source}: {result.status}\")\n",
    "\n",
    "# Read the XML file into a DataFrame and show it\n",
    "df = (\n",
    "    session\n",
    "    .read\n",
    "    .option('STRIP_OUTER_ELEMENT', True) # Strips TPCDI:Actions\n",
    "    .xml(f\"{stage_path}/CustomerMgmt.xml\")\n",
    "    .show(1, 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowflake does not support simple dot notation for XML the way it does for JSON.\n",
    "\n",
    "Instead we have to pair the `GET()` function with an `XMLGET()`, which can be quite tedious.\n",
    "\n",
    "So we can create helper functions to abstract the toil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplifies retrieving XML elements\n",
    "def get_xml_element(\n",
    "        column:str,\n",
    "        element:str,\n",
    "        datatype:str,\n",
    "        with_alias:bool = True\n",
    "):\n",
    "    new_element = (\n",
    "        get(\n",
    "            xmlget(\n",
    "                col(column),\n",
    "                lit(element),\n",
    "            ),\n",
    "            lit('$')\n",
    "        )\n",
    "        .cast(datatype)\n",
    "    )\n",
    "\n",
    "    # alias needs to be optional\n",
    "    return (\n",
    "        new_element.alias(element) if with_alias else new_element\n",
    "    )\n",
    "\n",
    "# Simplifies retrieving XML attributes\n",
    "def get_xml_attribute(\n",
    "        column:str,\n",
    "        attribute:str,\n",
    "        datatype:str,\n",
    "        with_alias:bool = True\n",
    "):\n",
    "    new_attribute = (\n",
    "        get(\n",
    "            col(column),\n",
    "            lit(f\"@{attribute}\")\n",
    "        )\n",
    "        .cast(datatype)\n",
    "    )\n",
    "\n",
    "    # alias needs to be optional\n",
    "    return (\n",
    "        new_attribute.alias(attribute) if with_alias else new_attribute\n",
    "    )\n",
    "\n",
    "# Constructs a phone number from multiple nested fields\n",
    "def get_phone_number(\n",
    "        phone_id:str,\n",
    "        separator:str = '-'\n",
    "):\n",
    "    return (\n",
    "        concat (\n",
    "            get_xml_element(f\"phone{phone_id}\", 'C_CTRY_CODE', 'STRING', False),\n",
    "            when(get_xml_element(f\"phone{phone_id}\", 'C_CTRY_CODE', 'STRING', False) == '', '')\n",
    "            .otherwise(separator),\n",
    "            get_xml_element(f\"phone{phone_id}\", 'C_AREA_CODE', 'STRING', False),\n",
    "            when(get_xml_element(f\"phone{phone_id}\", 'C_AREA_CODE', 'STRING', False) == '', '')\n",
    "            .otherwise(separator),\n",
    "            get_xml_element(f\"phone{phone_id}\", 'C_LOCAL', 'STRING', False),\n",
    "            when(get_xml_element(f\"phone{phone_id}\", 'C_EXT', 'STRING', False) == '', '')\n",
    "            .otherwise(\" ext: \"),\n",
    "            get_xml_element(f\"phone{phone_id}\", 'C_EXT', 'STRING', False)\n",
    "        )\n",
    "        .alias(f\"c_phone_{phone_id}\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put it all together and create our `customer_mgmt` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'customer_mgmt'\n",
    "df = (\n",
    "    session\n",
    "    .read\n",
    "    .option('STRIP_OUTER_ELEMENT', True) # Strips the TPCDI:Actions node\n",
    "    .xml(f\"{stage_path}/CustomerMgmt.xml\")\n",
    "    .select(\n",
    "        # flatten out all of the nested elements\n",
    "        xmlget(col('$1'), lit('Customer'), 0).alias('customer'),\n",
    "        xmlget(col('customer'), lit('Name'), 0).alias('name'),\n",
    "        xmlget(col('customer'), lit('Address'), 0).alias('address'),\n",
    "        xmlget(col('customer'), lit('ContactInfo'), 0).alias('contact_info'),\n",
    "        xmlget(col('contact_info'), lit('C_PHONE_1')).alias('phone1'),\n",
    "        xmlget(col('contact_info'), lit('C_PHONE_2')).alias('phone2'),\n",
    "        xmlget(col('contact_info'), lit('C_PHONE_3')).alias('phone3'),\n",
    "        xmlget(col('customer'), lit('TaxInfo'), 0).alias('tax_info'),\n",
    "        xmlget(col('customer'), lit('Account'), 0).alias('account'),\n",
    "        # get the Action attributes\n",
    "        get_xml_attribute('$1','ActionType','STRING'),\n",
    "        get_xml_attribute('$1','ActionTS','STRING'),\n",
    "    )\n",
    "    .select(\n",
    "        # Handling Action attributes\n",
    "        to_timestamp(\n",
    "            col('ActionTs'),\n",
    "            lit('yyyy-mm-ddThh:mi:ss')\n",
    "        ).alias('action_ts'),\n",
    "        col('ActionType').alias('ACTION_TYPE'),\n",
    "        # Get Customer Attributes\n",
    "        get_xml_attribute('customer','C_ID','NUMBER'),\n",
    "        get_xml_attribute('customer','C_TAX_ID','STRING'),\n",
    "        get_xml_attribute('customer','C_GNDR','STRING'),\n",
    "        # Had to disable auto-aliasing\n",
    "        try_cast(\n",
    "            get_xml_attribute('customer','C_TIER','STRING', False),\n",
    "            'NUMBER'\n",
    "        ).alias('c_tier'),\n",
    "        get_xml_attribute('customer','C_DOB','DATE'),\n",
    "        # Get Name elements\n",
    "        get_xml_element('name','C_L_NAME','STRING'),\n",
    "        get_xml_element('name','C_F_NAME','STRING'),\n",
    "        get_xml_element('name','C_M_NAME','STRING'),\n",
    "        # Get Address elements\n",
    "        get_xml_element('address','C_ADLINE1','STRING'),\n",
    "        get_xml_element('address', 'C_ADLINE2', 'STRING'),\n",
    "        get_xml_element('address','C_ZIPCODE','STRING'),\n",
    "        get_xml_element('address','C_CITY','STRING'),\n",
    "        get_xml_element('address','C_STATE_PROV','STRING'),\n",
    "        get_xml_element('address','C_CTRY','STRING'),\n",
    "        # Get Contact Info elements\n",
    "        get_xml_element('contact_info','C_PRIM_EMAIL','STRING'),\n",
    "        get_xml_element('contact_info','C_ALT_EMAIL','STRING'),\n",
    "        # Contruct phone numbers from multi-nested elements\n",
    "        get_phone_number('1'),\n",
    "        get_phone_number('2'),\n",
    "        get_phone_number('3'),\n",
    "        # Get TaxInfo elements\n",
    "        get_xml_element('tax_info','C_LCL_TX_ID','STRING'),\n",
    "        get_xml_element('tax_info','C_NAT_TX_ID','STRING'),\n",
    "        # Get Account Attributes\n",
    "        get_xml_attribute('account','CA_ID','STRING'),\n",
    "        get_xml_attribute('account','CA_TAX_ST','NUMBER'),\n",
    "        # Get Account elements\n",
    "        get_xml_element('account','CA_B_ID','NUMBER'),\n",
    "        get_xml_element('account','CA_NAME','STRING'),\n",
    "    )\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table(table_name)\n",
    ")\n",
    "\n",
    "print(f\"{table_name.upper()} table created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    session\n",
    "    .table('customer_mgmt')\n",
    "    .select(\n",
    "        col('action_ts'),\n",
    "        col('c_id'),\n",
    "        col('c_tier'),\n",
    "        col('c_phone_1')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ETL Diagram](images/tpc-di-logical-model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d9973-dcdb-491f-82d2-0a1ec2d133aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# When we Google \"dbt dynamic tables\":\n",
    "\n",
    "![Google Search](images/dbt-dynamic-tables.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ac995-dcdf-4d7d-96d8-4f23eafc16c9",
   "metadata": {},
   "source": [
    "# It's not as simple as this\n",
    "\n",
    "![Conflict](images/refresh-conflict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4236c-46da-4b50-aa37-225df6ff9f7f",
   "metadata": {},
   "source": [
    "# dbt is more than just a job scheduler.\n",
    "Dynamic Tables need to be (re)created in the correct order.\n",
    "The dependent relationships become very complex as the number of dependencies increases.\n",
    "We don't want to maintain a create script with all the tables in the correct order.\n",
    "\n",
    "dbt understands your DAG and can infer the relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dbt DAG](images/dbt-dag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f485d-792c-46df-906f-cd09f364d7d0",
   "metadata": {},
   "source": [
    "### Enabling dynamic tables in our dbt project\n",
    "Be on version `1.7.0` of `dbt-snowflake` and set a new materialization type in our `dbt_project.yml` file:\n",
    "\n",
    "```yaml\n",
    "models:\n",
    "  dbt_tpcdi:\n",
    "    example:\n",
    "      +materialized: view\n",
    "    bronze:\n",
    "      +schema: bronze\n",
    "      +materialized: dynamic_table\n",
    "      +snowflake_warehouse: tpcdi_large\n",
    "      +target_lag: downstream\n",
    "    silver:\n",
    "      +schema: silver\n",
    "      +materialized: dynamic_table\n",
    "      +snowflake_warehouse: tpcdi_large\n",
    "      +target_lag: '10 minutes'\n",
    "    gold:\n",
    "      +schema: gold\n",
    "      +materialized: dynamic_table\n",
    "      +snowflake_warehouse: tpcdi_large\n",
    "      +target_lag: '20 minutes'\n",
    "    work:\n",
    "      +schema: work\n",
    "      +materialized: ephemeral\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420db6a7-ce06-4638-a3a5-1ac16aff2fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!dbt build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb79852",
   "metadata": {},
   "source": [
    "### dbt also has Tests\n",
    "\n",
    "We can run them when we create the Dynamic Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62811a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!dbt build --select fact_trade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564eded",
   "metadata": {},
   "source": [
    "Or we can schedule them to run periodically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40309e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!dbt test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f442b",
   "metadata": {},
   "source": [
    "### dbt is more than a scheduler\n",
    "\n",
    "1. Cloud development environment for those that prefer it.\n",
    "1. CI/CD workflows for promoting Dynamic Table changes into Production.\n",
    "1. Perhaps there's promise in the Semantic Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowflake has its own version of the DAG\n",
    "However, this only exists after all the Dynamic Tables have been created.\n",
    "dbt understands the DAG _before_ it's created.\n",
    "\n",
    "![Snowflake DAG](images/snowflake-dag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22101a49",
   "metadata": {},
   "source": [
    "# Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a912a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tpcdi.py drop-schema --schema dl_gold\n",
    "!python tpcdi.py drop-schema --schema dl_silver\n",
    "!python tpcdi.py drop-schema --schema dl_bronze\n",
    "!python tpcdi.py drop-schema --schema dl_work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
